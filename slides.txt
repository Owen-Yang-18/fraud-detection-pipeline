Ph.D. Student in Computer Science at Duke University (2nd year)

Advised by Professor Jian Pei


Research Focus: Multimodal data mining, data storytelling, and bioinformatics

Current work: Automatic paradox discovery and pattern recognition in sparse data


Background: B.S. in Computer Science from Emory University
Publications: 5+ papers at top-tier conferences (KDD, CHIL, PSB, BHI)
Experience: Teaching Assistant for databases and algorithms courses
Currently seeking: Summer 2025 internship opportunities in data science/ML




Dataset Scale & Timeline:

17,341 total Android samples collected from December 2017 - December 2018
13,077 samples successfully analyzed dynamically
11,598 samples in final processed dataset


Data Sources: Multi-source collection approach

VirusTotal service, Contagio security blog, AMD, MalDozer
Additional datasets from recent research contributions


Malware Categories (5 distinct types):

Adware: Hidden advertising in legitimate apps, continuous pop-ups
Banking Malware: Trojan-based, mimics banking apps to steal credentials
SMS Malware: Exploits SMS services for C&C communication and data theft
Riskware: Legitimate programs exploitable by malicious users
Benign: Non-malicious applications verified through VirusTotal


Final Dataset Distribution:

Adware: 1,253 samples | Banking: 2,100 samples | SMS: 3,904 samples
Riskware: 2,546 samples | Benign: 1,795 samples


Analysis Methodology:

Dynamic Analysis: CopperDroid VMI-based system for behavior reconstruction
Static Analysis: Comprehensive feature extraction from APK files
Network Analysis: PCAP traffic capture during execution


Comprehensive Feature Sets:

470 behavioral features: System calls, binder calls, composite behaviors
139 system call features: Focused on system-level interactions
50,621 static features: Permissions, APIs, intents, services, file types, obfuscation patterns


Available Resources:

Original APK files, JSON analysis logs, structured CSV feature files
Publicly available for cybersecurity research and AI/ML applications


Key Advantages: Most comprehensive static + dynamic feature coverage compared to existing public datasets

what is the motivation that we use machine learning methods like deep graph neural network to perform malware classification on this dataset? why we perform classification leveraging the static features and also the temporal apk json log. can you provide a comprehensive bullet point argument that fit into one slide? the goal is to make ml detection on edge device. so one constrain is to make ml model small and runnable on device. also we have massive amount of log and apks


Why Deep Graph Neural Networks for Android Malware Detection?
• Traditional Detection Limitations:

Signature-based methods fail against polymorphic and zero-day malware
Rule-based systems cannot adapt to evolving attack patterns
Manual feature engineering insufficient for complex malware behaviors

• Graph Neural Network Advantages:

Structural Representation: Naturally models app components (APIs, permissions, intents) as interconnected graphs
Relational Learning: Captures complex dependencies between malware features that linear models miss
Scalability: Efficiently processes massive datasets (17K+ samples) through batch graph operations

• Multi-Modal Feature Integration:

Static Features: 50K+ features provide comprehensive app fingerprint at analysis time
Dynamic Temporal Logs: JSON logs capture real-time behavioral patterns and attack sequences
Synergistic Effect: Combined static+dynamic analysis achieves higher detection accuracy than either alone

• Edge Device Deployment Benefits:

Real-time Protection: On-device detection eliminates cloud dependency and network latency
Privacy Preservation: Sensitive app data never leaves the device
Offline Capability: Works without internet connectivity
Reduced Infrastructure Costs: No cloud processing overhead

• Model Optimization for Edge Constraints:

Graph Compression: Pruning techniques reduce model size while maintaining accuracy
Knowledge Distillation: Transfer learning from large models to lightweight edge variants
Efficient Architectures: Specialized GNN designs optimized for mobile hardware limitations

• Handling Massive Scale:

Incremental Learning: Models update with new malware samples without full retraining
Distributed Processing: Parallel graph analysis across device clusters
Automated Feature Selection: ML identifies most discriminative features from 50K+ static attributes

Bottom Line: GNNs uniquely combine structural reasoning, multi-modal fusion, and scalable processing to achieve high-accuracy malware detection suitable for resource-constrained edge deployment.

can you explain more on the csv file gathering the static feature. here each row in the csv is an apk, each column represent one of a system call, binder call, or composite behaviors. each cell in the csv represent the total number of time or frequencies an apk make such a call over the two minute recording time. also, explain how we do feature engineering. for each feature or for each column of the csv, we group hte row by their classes, and model their separate per class distribution of frequenceis. then we use jensen shannon divergence to calculate the pairwise distribution agreement across different classes. a feature is more helpful for classifcation or more distinguishing if cross class distribution have higher disagreement i.e., jesen shannon divergence. can you frame it into a bullet point that fit into at most half a slide? 

Here's a concise explanation of the CSV structure and feature engineering approach:

**Static Feature CSV Structure & Feature Engineering**

**• CSV Data Format:**
  - **Rows:** Individual APK samples (11,598 total)
  - **Columns:** System calls, binder calls, and composite behaviors (470 features)
  - **Cell Values:** Frequency counts of each behavior during 2-minute dynamic analysis

**• Feature Engineering via Jensen-Shannon Divergence:**
  - **Step 1:** Group APK samples by malware class (Adware, Banking, SMS, Riskware, Benign)
  - **Step 2:** For each feature column, model frequency distribution per class
  - **Step 3:** Calculate Jensen-Shannon divergence between all class distribution pairs
  - **Step 4:** Higher JS divergence = more discriminative feature for classification

**• Feature Selection Rationale:**
  - **High Divergence Features:** Different malware classes exhibit distinct behavioral patterns
  - **Low Divergence Features:** Similar frequency distributions across classes (less useful)
  - **Automated Ranking:** JS divergence scores enable systematic feature importance ranking

**• Benefits for ML Model:**
  - **Dimensionality Reduction:** Focus on most distinguishing features for edge deployment
  - **Class Separability:** Enhanced model performance through statistically validated feature selection
  - **Computational Efficiency:** Fewer features = smaller, faster models suitable for mobile devices

**Key Insight:** Behavioral frequency patterns captured during dynamic analysis reveal class-specific signatures that enable robust malware classification.