Ph.D. Student in Computer Science at Duke University (2nd year)

Advised by Professor Jian Pei


Research Focus: Multimodal data mining, data storytelling, and bioinformatics

Current work: Automatic paradox discovery and pattern recognition in sparse data


Background: B.S. in Computer Science from Emory University
Publications: 5+ papers at top-tier conferences (KDD, CHIL, PSB, BHI)
Experience: Teaching Assistant for databases and algorithms courses
Currently seeking: Summer 2025 internship opportunities in data science/ML




Dataset Scale & Timeline:

17,341 total Android samples collected from December 2017 - December 2018
13,077 samples successfully analyzed dynamically
11,598 samples in final processed dataset


Data Sources: Multi-source collection approach

VirusTotal service, Contagio security blog, AMD, MalDozer
Additional datasets from recent research contributions


Malware Categories (5 distinct types):

Adware: Hidden advertising in legitimate apps, continuous pop-ups
Banking Malware: Trojan-based, mimics banking apps to steal credentials
SMS Malware: Exploits SMS services for C&C communication and data theft
Riskware: Legitimate programs exploitable by malicious users
Benign: Non-malicious applications verified through VirusTotal


Final Dataset Distribution:

Adware: 1,253 samples | Banking: 2,100 samples | SMS: 3,904 samples
Riskware: 2,546 samples | Benign: 1,795 samples


Analysis Methodology:

Dynamic Analysis: CopperDroid VMI-based system for behavior reconstruction
Static Analysis: Comprehensive feature extraction from APK files
Network Analysis: PCAP traffic capture during execution


Comprehensive Feature Sets:

470 behavioral features: System calls, binder calls, composite behaviors
139 system call features: Focused on system-level interactions
50,621 static features: Permissions, APIs, intents, services, file types, obfuscation patterns


Available Resources:

Original APK files, JSON analysis logs, structured CSV feature files
Publicly available for cybersecurity research and AI/ML applications


Key Advantages: Most comprehensive static + dynamic feature coverage compared to existing public datasets

what is the motivation that we use machine learning methods like deep graph neural network to perform malware classification on this dataset? why we perform classification leveraging the static features and also the temporal apk json log. can you provide a comprehensive bullet point argument that fit into one slide? the goal is to make ml detection on edge device. so one constrain is to make ml model small and runnable on device. also we have massive amount of log and apks


Why Deep Graph Neural Networks for Android Malware Detection?
• Traditional Detection Limitations:

Signature-based methods fail against polymorphic and zero-day malware
Rule-based systems cannot adapt to evolving attack patterns
Manual feature engineering insufficient for complex malware behaviors

• Graph Neural Network Advantages:

Structural Representation: Naturally models app components (APIs, permissions, intents) as interconnected graphs
Relational Learning: Captures complex dependencies between malware features that linear models miss
Scalability: Efficiently processes massive datasets (17K+ samples) through batch graph operations

• Multi-Modal Feature Integration:

Static Features: 50K+ features provide comprehensive app fingerprint at analysis time
Dynamic Temporal Logs: JSON logs capture real-time behavioral patterns and attack sequences
Synergistic Effect: Combined static+dynamic analysis achieves higher detection accuracy than either alone

• Edge Device Deployment Benefits:

Real-time Protection: On-device detection eliminates cloud dependency and network latency
Privacy Preservation: Sensitive app data never leaves the device
Offline Capability: Works without internet connectivity
Reduced Infrastructure Costs: No cloud processing overhead

• Model Optimization for Edge Constraints:

Graph Compression: Pruning techniques reduce model size while maintaining accuracy
Knowledge Distillation: Transfer learning from large models to lightweight edge variants
Efficient Architectures: Specialized GNN designs optimized for mobile hardware limitations

• Handling Massive Scale:

Incremental Learning: Models update with new malware samples without full retraining
Distributed Processing: Parallel graph analysis across device clusters
Automated Feature Selection: ML identifies most discriminative features from 50K+ static attributes

Bottom Line: GNNs uniquely combine structural reasoning, multi-modal fusion, and scalable processing to achieve high-accuracy malware detection suitable for resource-constrained edge deployment.

can you explain more on the csv file gathering the static feature. here each row in the csv is an apk, each column represent one of a system call, binder call, or composite behaviors. each cell in the csv represent the total number of time or frequencies an apk make such a call over the two minute recording time. also, explain how we do feature engineering. for each feature or for each column of the csv, we group hte row by their classes, and model their separate per class distribution of frequenceis. then we use jensen shannon divergence to calculate the pairwise distribution agreement across different classes. a feature is more helpful for classifcation or more distinguishing if cross class distribution have higher disagreement i.e., jesen shannon divergence. can you frame it into a bullet point that fit into at most half a slide? 

Here's a concise explanation of the CSV structure and feature engineering approach:

**Static Feature CSV Structure & Feature Engineering**

**• CSV Data Format:**
  - **Rows:** Individual APK samples (11,598 total)
  - **Columns:** System calls, binder calls, and composite behaviors (470 features)
  - **Cell Values:** Frequency counts of each behavior during 2-minute dynamic analysis

**• Feature Engineering via Jensen-Shannon Divergence:**
  - **Step 1:** Group APK samples by malware class (Adware, Banking, SMS, Riskware, Benign)
  - **Step 2:** For each feature column, model frequency distribution per class
  - **Step 3:** Calculate Jensen-Shannon divergence between all class distribution pairs
  - **Step 4:** Higher JS divergence = more discriminative feature for classification

**• Feature Selection Rationale:**
  - **High Divergence Features:** Different malware classes exhibit distinct behavioral patterns
  - **Low Divergence Features:** Similar frequency distributions across classes (less useful)
  - **Automated Ranking:** JS divergence scores enable systematic feature importance ranking

**• Benefits for ML Model:**
  - **Dimensionality Reduction:** Focus on most distinguishing features for edge deployment
  - **Class Separability:** Enhanced model performance through statistically validated feature selection
  - **Computational Efficiency:** Fewer features = smaller, faster models suitable for mobile devices

**Key Insight:** Behavioral frequency patterns captured during dynamic analysis reveal class-specific signatures that enable robust malware classification.

can you also explain how we select temporal features? basically we analyse, for each one of system call, binder call, and composite behavior, we analyze the sequence. we calculate the l2 difference across each apk from each pair of class. if two sequences are different, it means it is more useful for classification. can you write a similar style of bullet point for one slide? make it verbose and comprehensive.

Temporal Feature Selection via Sequence Analysis
• Temporal Sequence Extraction:

Input: Dynamic execution logs capturing chronological order of behaviors
Sequences: Time-ordered system calls, binder calls, and composite behaviors per APK
Window: 2-minute recording captures complete malware execution patterns

• Cross-Class Sequence Comparison Methodology:

Step 1: Extract temporal sequences for each behavior type across all APK samples
Step 2: Group sequences by malware class (Adware, Banking, SMS, Riskware, Benign)
Step 3: Calculate L2 distance between sequence pairs from different classes
Step 4: Aggregate L2 distances across all possible class combinations per feature

• Feature Discriminability Assessment:

High L2 Distance: Sequences exhibit distinct temporal patterns across classes
Low L2 Distance: Similar execution timing regardless of malware type
Ranking Criterion: Features with larger cross-class sequence differences = more classification value

based on this dataset, i created a heterogeneous graph, where we have a type of node representing apks, another type for system call, another type for binder call, and another type for composite calls. for each apk node we create an edge to the system call, binder call or composite behavior node if in the csv file it makes at least one such call. the edge weight is the frequenceis in the csv. therefore, our ml goal is to perform node classification on the apk nodes. can you present this into a few bullet point for half a slide please.

Graph Structure Design:

4 Node Types: APK nodes, System call nodes, Binder call nodes, Composite behavior nodes
Edge Creation: APK connects to behavior node if frequency ≥ 1 in CSV
Edge Weights: Frequency values from CSV (behavioral occurrence counts)

• Graph Properties:

Heterogeneous: Multiple node types capture different aspects of malware behavior
Weighted: Edge weights preserve frequency information for nuanced analysis
Bipartite-like: APKs connect to behaviors, but behaviors don't interconnect

• Machine Learning Task:

Objective: Node classification on APK nodes (predict malware class)
Input Features: Graph structure + edge weights encode APK-behavior relationships
Output: 5-class prediction (Adware, Banking, SMS, Riskware, Benign)

what is the advantage of using graph neural network and graph machine learning approched over using tabular data with basic feed forward or multi layer perceptron? also we implement the graph using pytorch geometric library an extension of pytorch. explain this using a bullet point for slideshow.

Graph Neural Networks vs. Traditional Tabular ML Approaches
• Relational Learning Advantages:

MLPs: Treat each APK independently, missing cross-sample behavioral patterns
GNNs: Learn from shared behaviors across APKs, leveraging collective intelligence
Benefit: APKs using similar attack vectors inform each other's classification

• Feature Interaction Modeling:

MLPs: Limited ability to capture complex feature interactions beyond linear combinations
GNNs: Message passing naturally models non-linear behavioral dependencies
Benefit: Captures sophisticated malware strategies that combine multiple behaviors

• Sparse Data Handling:

MLPs: Struggle with 470-dimensional sparse feature vectors (many zero frequencies)
GNNs: Graph structure explicitly represents only existing APK-behavior connections
Benefit: Efficient representation and processing of sparse behavioral data

• Inductive Bias & Generalization:

MLPs: No structural assumptions about feature relationships
GNNs: Graph structure provides domain-appropriate inductive bias for behavioral analysis
Benefit: Better generalization to unseen malware variants with similar behavioral patterns

• Implementation with PyTorch Geometric:

Specialized Library: Purpose-built for graph neural networks with optimized operations
Scalability: Efficient batch processing of large heterogeneous graphs
Flexibility: Supports various GNN architectures (GraphSAGE, GAT, HeteroConv) for experimentation

so my experiment results have shown that using heterogeneous weighted graph approach with heterogeneous graph neural network can achieve very promising very good classification performance. so as for a concluding slide. my discussion should cover the following question. (1) can we get these signals (i.e., system call, binder, composite call behaviors) from a Samsung android device. (2) how should we count these low level events (calls) on device (like phones). (3) how often the graph snapshot should be updated (it looks like per second snapshot in the temporal setup cannot achieve as good as a performance compared to static 2 min setup, so a snapshot can last for 2 mins assuming the behavior and counts are similar every 2 mins) (4) what is the difference between RDFox and PyTorch Geometric, in this application, what is the different target and use case for RDFox and PyTorch Geometric. please use web search to frame your response. your response should be a bullet point that can fit into one or two slides of presentations.


Concluding Discussion: Deployment & Implementation Considerations
• On-Device Signal Collection:

Background Processing: Continuous monitoring without user interference or performance impact
Small Footprint Requirement: Minimal CPU, memory, and battery usage for production deployment
Implementation: Lightweight monitoring agent collecting behavioral counts (system calls, binder calls) in 2-minute windows
Challenge: Balance comprehensive data collection with resource constraints on mobile devices

• Graph Snapshot Update Frequency:

Temporal graph research shows snapshot intervals significantly impact detection performance Encrypted Malware Traffic Detection via Graph-based Network Analysis | Proceedings of the 25th International Symposium on Research in Attacks, Intrusions and Defenses
Finding: Static 2-minute snapshots outperform per-second updates for malware behavioral analysis
Reason: Most benign and malware temporal sequences are similar - attacks happen at peculiar time instances, making temporal patterns less discriminative than frequency-based features
Implementation: Update heterogeneous graph every 2 minutes with aggregated behavioral data

• Machine Learning Model Inference:

Background Operation: Real-time malware classification without affecting device performance
Edge Optimization: Compressed GNN models suitable for mobile hardware constraints
Small Footprint: Model pruning, quantization, and efficient architectures for minimal resource usage
Continuous Protection: Ongoing threat detection with imperceptible system impact

• RDFox vs. PyTorch Geometric - Fundamentally Different Purposes:

PyTorch Geometric:

Role: Machine learning framework for training graph neural networks
Use Case: Research, model development, training heterogeneous GNNs on malware data
Comprehensive GNN library with support for heterogeneous graphs and various architectures


RDFox:

Role: Knowledge graph database for storing and reasoning about cybersecurity facts (CVEs, attack patterns, CAPEC) SpringerSpringer
Use Case: Reasoning about attack relationships, vulnerability chains, and threat intelligence MDPIMDPI
Example Applications: "Which CVEs are linked to this attack pattern?" or "What CAPEC techniques could follow this vulnerability?" Cybersecurity knowledge graphs | Knowledge and Information Systems



• Integration Strategy:

PyTorch Geometric: Train your heterogeneous GNN model for malware classification
RDFox: Store threat intelligence and reasoning rules about attack patterns/CVEs
Combined System: Background GNN detects malware → RDFox reasons about attack implications and defensive strategies